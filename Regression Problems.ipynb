{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression \n",
    "\n",
    "The purpose of this problem set is to put your regression skills to the test. As a GA student of data science, you have covered a number of sklearn regression techniques, so now is your chance to apply them. We'll be using the Boston Housing Dataset. Just kidding. I know you hate that one. \n",
    "\n",
    "We'll be exploring the relationships between sugar, economics, and teeth. You are given a dataset containing sugar consuption, healthcare spending, per capita GDP, literacy rate and the number of bad teeth per child across several hundred countries. What do you think? If you get richer, do your teeth get worse from more sugary foods, or better with health care assistance? Does education improve health, or drive excess? \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/brush.gif' width='150'>\n",
    "\n",
    "You'll be implementing some of the techniques you've learned in class with hypothesis testing, exploratory analysis, and regression. A few questions to consider: \n",
    " \n",
    "    1) What questions are relevant to ask? How do explore these your initial analysis?\n",
    "    2) You have only one data set. How do you split it into training and testing data?\n",
    "    3) How can you optimize on the default regression techniques? \n",
    "    4) How will you prevent overfitting? (Hint: look at the other files in this directory)\n",
    "    5) How can you effectively visualize the relationships?\n",
    "    6) How do the parameters of your regression explain your hypothesis?\n",
    "    \n",
    "I've provided some imports and starter code to get you going. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dental_economics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n",
    "You've seen the data. What are the features and what is the output? Explain your hypotheses here: \n",
    "\n",
    "### H0: \n",
    "\n",
    "### H1: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your models \n",
    "\n",
    "split the data for training and testing, test the regressors,visualize, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Check \n",
    "\n",
    "How's the model building coming? Have you identifyed some features of interest and noticed any trends? If so, put them into words. \n",
    "\n",
    "### Noticeable Trends: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's see how your models are doing.  \n",
    "\n",
    "Evaluate your models using cross-validation. Below is some code to get you started. In a sentence, explain what these results mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc') #repeat for all your models \n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Time to fine tune the model. What hyperparameters exist in your model? How do you tune these hyperparameters? Also, how can you test for overfitting, and how will you reduce it if you see it? Implement below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaling weights between 0-1 is necessary when updating weights. This piece of code might be useful. \n",
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your models again. How do different hyperparameters change your predictive performance? Again, explain in a few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for INPUT HYPERPARAMTER in range(INPUT RANGE):\n",
    "    model = \n",
    "    scores = cross_val_score(model, X, y, scoring='roc_auc')\n",
    "    print('n trees: {}, CV AUC {}, Average AUC {}'.format(n_trees, scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Conclusions\n",
    "\n",
    "If a data scientist makes a brilliant conclusion but can't communicate effectively, did they ever make a conclusion?  \n",
    "\n",
    "Explain your findings to a person with a math/stats background. Reference your H1/H0 hypotheses: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explain them to a person who hates math:  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
