{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators \n",
    "\n",
    "In this tutorial we will be going over generators and how the can be advantageous over lists, especailly when we are trying to do a very memory intensive operation. Additionally, some find the generator to be more readable, since it is a bit less verbose and doens't deal with list initializations. \n",
    "\n",
    "To show this advantage, lets take the following example. Below is a function that takes in a list as an arguent, loops through that list, squares each value and appends in to a new list, `result`, and returns the new list.\n",
    "\n",
    "#### A Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_list(in_list): \n",
    "    result = []\n",
    "    for i in in_list: \n",
    "        result.append(i**2)\n",
    "    return result\n",
    "\n",
    "test_list = [1, 2, 3, 4, 5, 6]\n",
    "square_list(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple. Let's convert this function to a generator, which will be a lot less verbose. We will get rid of all instances of the `result` output list completely, and replace it with one keyword, `yield`, instead of the appending. Yield is what makes the function a generator. \n",
    "\n",
    "#### The Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen_func_square at 0x00000139E9686518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_func_square(in_list): \n",
    "    for i in in_list: \n",
    "        #yield the next result \n",
    "        yield (i**2)\n",
    "        \n",
    "gen_func_square(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. We did not get what we expect. Calling the function returned a generator object, not a list. This is because the generator function yields the result one at a time. The generator is waiting for us to ask for a result. We can ask for new results by creating the generator object and calling the `next` keyword on it. Each time we call next, we will make one pass through the loop.\n",
    "\n",
    "This is meaningful because by only having the generator object, it means the output list is not held in memory. If we know that our output is a huge, memory intensive value (think machine learning data or IoT applications where memory real estate is precious), we can use generators to only draw new values sequentially, and save that memory. \n",
    "\n",
    "#### Passing through the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#create the generator object, assign to variable \n",
    "gen_object = gen_func_square(test_list)\n",
    "\n",
    "#sequentially pass through generator object with next \n",
    "print (next(gen_object))\n",
    "print (next(gen_object))\n",
    "print (next(gen_object))\n",
    "print (next(gen_object))\n",
    "print (next(gen_object))\n",
    "print (next(gen_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Iteration\n",
    "\n",
    "But what if I was to call `next` one more time, after we have passed through the entire list? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-63cb49d3f50b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print (next(gen_object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This StopIteration exception means that the generator has been exhausted and it is out of values. \n",
    "\n",
    "Now this was a nice toy example, but manually stepping through the iteration is pretty cumbersome and doesn't really save anytime. We can also use `next` and pass through the generator using a for loop. The nice thing about this is that the for loop knows when to stop and will not run into the StopIteration exception. \n",
    "\n",
    "#### Loop through a generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "#need to recreate gen object since it was previously exhausted\n",
    "gen_object = gen_func_square(test_list)\n",
    "\n",
    "for square in gen_object: \n",
    "    print (square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Larger Example\n",
    "\n",
    "Okay, that was just an introduction to generators, but to behold their true power, we need to be doing more memory intensive tasks. Let see an example, where I take the average of a vector that is 100 values long. I do this 1 million times, something that can be quite common in programming projects at scale, append the average to a running list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import random\n",
    "import numpy as np\n",
    "from pympler import asizeof #memory profiler \n",
    "\n",
    "#loop through length of how_long\n",
    "#calculate mean of random vector \n",
    "#append that mean to a running list \n",
    "\n",
    "def mean_list(how_long):    \n",
    "    means = []\n",
    "    for i in range(how_long):\n",
    "        #create vector of 100 random numbers range=[0, 100]\n",
    "        vec = np.random.uniform(0, 100, size=100)\n",
    "        avg = np.mean(vec)\n",
    "        means.append(avg)\n",
    "    return means \n",
    "\n",
    "#do the same with a generator \n",
    "def mean_gen(how_long):    \n",
    "    for i in range(how_long):\n",
    "        vec = np.random.uniform(0, 100, size=100)\n",
    "        yield np.mean(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to worry too much about the code below to understand what it is doing. Basically I am running the list function defined above, timing it, and probing how much memory the returned list object takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process took 12.05374617283951 seconds\n",
      "process used 40.697464 megabytes\n"
     ]
    }
   ],
   "source": [
    "#here I am just timing how long it takes to run the function \n",
    "start_time = time.clock()\n",
    "test_avg = mean_list(1000000)\n",
    "end_time = time.clock()\n",
    "\n",
    "#and the memory it uses \n",
    "byte_size = asizeof.asizeof(test_avg)\n",
    "MB = byte_size/1000000\n",
    "\n",
    "print ('process took {} seconds'.format(end_time-start_time))\n",
    "print ('process used {} megabytes'.format(MB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Ok so 12 seconds and 41 megabytes to do the 1 million iterations. That's a lot. Now let's try the generator. Note that this is the same exact test code, but I just swap out mean_list with mean_gen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process took 9.283950623739656e-05 seconds\n",
      "process used 0 megabytes\n"
     ]
    }
   ],
   "source": [
    "#here I am just timing how long it takes to run the function \n",
    "start_time = time.clock()\n",
    "test_avg = mean_gen(1000000)\n",
    "end_time = time.clock()\n",
    "\n",
    "#and the memory it uses \n",
    "byte_size = asizeof.asizeof(test_avg)\n",
    "MB = byte_size/1000000.\n",
    "\n",
    "print ('process took {} seconds'.format(end_time-start_time))\n",
    "print ('process used {} bytes'.format(byte_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the time and memory useage are essentially negligible! To pass through the generator we can just use next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.759528296296253\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "test_avg = mean_gen(1000000)\n",
    "for i in test_avg: \n",
    "    pass\n",
    "end_time = time.clock()\n",
    "print ('process took {} seconds'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this took roughly the same around of time, but used waaay less memory. One drawback of not holding the entire list in memory is that we can not probe a particular index of the generator, the way we do a list. Like `my_list[3]`, grabbing the 4th index. We can still quickly get a list from the generator by calling `list()` on it, but then we lose the nice properties of a generator, since it is a list again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.452362059533428"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_gen_toList = list(mean_gen(10000))\n",
    "mean_gen_toList[5064]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, generators are most useful when we have a memory intensive task and you do not need hold on to the full results of your processing. An example is in machine learning, when you may need to loop through your data many times to train your model. You can still keep the results at the end with logging techniques (outside the scope of this tutorial), but you don't really care about how each individual data value was processed; just the end result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
